{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d1a4a7-8fed-4b43-93d8-346fda5d0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37dde7-1c1e-4759-9d80-fd5c5bd0fc14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c3529-bcc3-4b1a-9516-f03724b7235b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "008d9ffc-9969-4ef8-b6a9-351914abb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from datasets import Dataset,DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "SNIPS_DATA_BASE_URL = (\n",
    "    \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n",
    "    \"master/data/snips/\"\n",
    ")\n",
    "for filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)\n",
    "        \n",
    "lines_train = Path(\"train\").read_text(\"utf-8\").strip().splitlines()\n",
    "#lines_train[:5]\n",
    "\n",
    "def parse_line(line):\n",
    "    utterance_data, intent_label = line.split(\" <=> \")\n",
    "    items = utterance_data.split()\n",
    "    words = [item.rsplit(\":\", 1)[0]for item in items]\n",
    "    word_labels = [item.rsplit(\":\", 1)[1]for item in items]\n",
    "    return {\n",
    "        \"label\": intent_label,\n",
    "        \"text\": \" \".join(words),\n",
    "    }\n",
    "\n",
    "parsed = [parse_line(line) for line in lines_train]\n",
    "\n",
    "df_train = pd.DataFrame([p for p in parsed if p is not None])\n",
    "\n",
    "lines_valid = Path(\"valid\").read_text(\"utf-8\").strip().splitlines()\n",
    "lines_test = Path(\"test\").read_text(\"utf-8\").strip().splitlines()\n",
    "\n",
    "df_valid = pd.DataFrame([parse_line(line) for line in lines_valid])\n",
    "df_test = pd.DataFrame([parse_line(line) for line in lines_test])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train.label = le.fit_transform(df_train.label)\n",
    "df_test.label = le.fit_transform(df_test.label)\n",
    "df_valid.label = le.fit_transform(df_valid.label)\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "id_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "dataset_valid = Dataset.from_pandas(df_valid)\n",
    "\n",
    "\n",
    "all_dataset = DatasetDict({\"train\":dataset_train, \"test\":dataset_test , \"validation\":dataset_valid})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247c327-bcab-4590-817d-6f6550c41c21",
   "metadata": {},
   "source": [
    "### CLINC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2587ecf3-170f-4347-8ae6-7fca665a907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset clinc_oos (/work/pi_adrozdov_umass_edu/syerawar_umass_edu/hf_cache/datasets/clinc_oos/small/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e031f64c854890a14c0a5b3d0bc78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading clinc dataset\n",
    "all_dataset = load_dataset(\"clinc_oos\", \"small\")\n",
    "all_dataset = all_dataset.rename_column(\"intent\", \"label\")\n",
    "\n",
    "# labels = clinc[\"train\"].features[\"label\"].names\n",
    "# label2id = {labels[i] : i for i in range(len(labels))}\n",
    "# id2label = {i: labels[i]  for i in range(len(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89067a57-1b7b-4b8c-81fd-263ab621fe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'what does assiduous mean', 'label': 139}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset[\"test\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c4e8f8-68f0-4e2f-ad18-be607091c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655f04bb-739f-4b66-8091-6dd47024d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a9f7d3-c3a6-4307-b560-810c770a5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59517975fd941cd9f0a0f6d3638ed5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7c3b7759043b0801a1ac3f359950a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc88fc9cebd4cdcb550b70b3f759316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = all_dataset.map(preprocess_function,batched= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa04f72e-058b-465c-bed4-4a7f08513dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28db9c9e-0c0f-480e-bca9-bc6ca203218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4816dd7a-12ec-43e3-ac00-4db3d4cf4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_imdb[\"train\"][1]\n",
    "tokenized_imdb = tokenized_imdb.remove_columns([\"text\"])\n",
    "tokenized_imdb = tokenized_imdb.rename_column(\"label\", \"labels\")\n",
    "tokenized_imdb.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9fd2d1-2ebd-4f3e-8f31-213609625a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c104bb92-2f33-4452-a3a0-2d4c05af3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c14bbed-5687-4fa5-bdae-b2d5d8293c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1c364a-1402-45f9-8a5d-9e0a3323bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.features.features.ClassLabel"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_dataset[\"train\"].features['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1dfa73-36bd-4376-bb20-c4926e602471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "\n",
    "label_names = sorted(set(labels for labels in all_dataset[\"train\"][\"label\"]))\n",
    "# label_names\n",
    "# Cast to ClassLabel\n",
    "# all_dataset = all_dataset.cast_column(\"label\", Sequence(ClassLabel(names=label_names)))\n",
    "\n",
    "\n",
    "# labels = all_dataset[\"train\"].features[\"label\"].names\n",
    "label2id = {\"Label_\"+str(i) : i for i in range(len(label_names))}\n",
    "id2label = {i: \"Label_\"+str(i)  for i in range(len(label_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19ad0aa5-10f6-4543-9c99-1a80586ae7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "# label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=len(label_names), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd10cd7-c1d2-4c30-9485-9fbe13e6b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d927925-4f59-4714-8a55-0a8082b6dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adb1b4b8-8b5b-4c5e-8cab-9639d56ce74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77312f7bf4f4b9594a5975e0de1d7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d05ef4-0efb-475b-bd74-96705d39a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb01a15-8fd5-4604-8e80-1184ce27f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_adrozdov_umass_edu/syerawar_umass_edu/envs/vadops/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92/950 01:02 < 09:59, 1.43 it/s, Epoch 0.19/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d49b434-8c75-43c8-abcb-31fd2e194b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(tokenized_imdb[\"train\"].shuffle(seed=42),shuffle = True,batch_size = 16)\n",
    "test_loader = DataLoader(tokenized_imdb[\"test\"].shuffle(seed=42),shuffle = True,batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8177ec2d-0385-4801-8963-a05a8a21bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),lr = 5e-5)\n",
    "num_epochs = 3\n",
    "num_steps = num_epochs*len(train_loader)\n",
    "lr_scheduler = get_scheduler(name=\"linear\",optimizer = optimizer, num_warmup_steps = 0,num_training_steps = num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77bbc441-c02c-4598-bd02-bcce8357d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73cb1cf-5f3e-474a-a3a7-6366612140dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4689/4689 [57:16<00:00,  1.59it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_steps))\n",
    "model.train()\n",
    "\n",
    "# print(len(train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        # print(batch)\n",
    "        # print(type(batch['input_ids']))\n",
    "        # for k,v in batch.items():\n",
    "        #     print(v)\n",
    "        #     break\n",
    "        bt = {k:torch.Tensor(v).to(device) for k,v in batch.items()}\n",
    "        out = model(**bt)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e434413-5725-4453-8fd4-74e7ed22d386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93396}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    bt = {k:torch.Tensor(v).to(device) for k,v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        out = model(**bt)\n",
    "        \n",
    "    logits = out.logits\n",
    "    predictions = torch.argmax(logits,dim=-1)\n",
    "    metric.add_batch(predictions = predictions,references = batch[\"labels\"])\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "379e08e9-a059-4ca1-9a55-7b5a758aeb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This was fine.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    \n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "036d6d13-9921-4f53-b36b-9be476fe22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert_imdb_3_1e5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef76349-b9f2-4de1-adc9-1ea8a8681f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (syerawar_umass_edu-vadops)",
   "language": "python",
   "name": "conda-env-syerawar_umass_edu-vadops-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
