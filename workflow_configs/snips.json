{
  "dataset_name": "snips",
  "pipeline_task": "text-classification",
  "workflow_output_dir": "../output",
  "steps": 3,
  "dynamics": ["train", "validation"],
  "eval" : ["train", "validation", "test"],
  "entropy": ["train", "validation", "test"],
  "generate_data_from": "train",
  "model_name_or_path": "roberta-base",
  "prompts":{
  	"prompt_llm":"ChatGPT",
	  "prompt_type":1,
    "eg_type":"f1-score",
	  "num_gen":20,
    "num_eg":2,
    "num_good":2,
    "num_bad":0
  },
  "training_args": {
    "learning_rate":2e-5,
    "per_device_train_batch_size":5,
    "per_device_eval_batch_size":5,
    "num_train_epochs": 10,
    "weight_decay":0.1,
    "evaluation_strategy":"epoch",
    "save_strategy":"epoch",
    "load_best_model_at_end": true,
    "save_total_limit" : 2,
    "seed": 42
  },
  "reinitiate_model_to_default": true
}
